# -*- coding: utf-8 -*-
"""English_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14dF-QHypUGwljn3ySMq0ZyBFKNyuI_BO
"""

!pip install pdfplumber

import pandas as pd
from transformers import pipeline
import pdfplumber
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Initialize the question generator model
question_generator = pipeline("text2text-generation", model="valhalla/t5-small-qa-qg-hl")

# Function to extract and clean text chunks from a PDF
def extract_clean_text_chunks_from_pdf(pdf_path, chunk_size=1000):
    text_chunks = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                page_text = re.sub(r'http\S+|www\S+|file:\S+|\S+\.html', '', page_text)
                page_text = re.sub(r'\s+', ' ', page_text).strip()
                for i in range(0, len(page_text), chunk_size):
                    text_chunks.append(page_text[i:i + chunk_size])
    return text_chunks

# Function to generate questions from text
def generate_questions(text, num_questions=15):
    formatted_text = "generate question: " + text
    questions = question_generator(formatted_text, max_length=100, num_beams=5, num_return_sequences=num_questions)
    return questions

# Function to retrieve relevant chunks
def retrieve_relevant_chunks(prompt, text_chunks, top_n=5):
    vectorizer = TfidfVectorizer().fit_transform([prompt] + text_chunks)
    cosine_similarities = cosine_similarity(vectorizer[0:1], vectorizer[1:]).flatten()
    top_n_indices = cosine_similarities.argsort()[-top_n:][::-1]
    relevant_chunks = [text_chunks[i] for i in top_n_indices]
    return relevant_chunks

# Main function to generate questions using prompt and PDF text
def generate_questions_from_prompt_with_rag(prompt, pdf_path, total_questions=20, top_n_chunks=5, questions_per_chunk=2):
    text_chunks = extract_clean_text_chunks_from_pdf(pdf_path)
    if not text_chunks:
        return []

    relevant_chunks = retrieve_relevant_chunks(prompt, text_chunks, top_n=top_n_chunks)
    if not relevant_chunks:
        return []

    all_generated_questions = set()
    for chunk in relevant_chunks:
        questions = generate_questions(chunk, num_questions=questions_per_chunk)
        for q in questions:
            cleaned_question = re.sub(r'\s+', ' ', q['generated_text']).strip()
            if len(cleaned_question) > 15:
                all_generated_questions.add(cleaned_question)

        if len(all_generated_questions) >= total_questions:
            break

    return list(all_generated_questions)[:total_questions]

