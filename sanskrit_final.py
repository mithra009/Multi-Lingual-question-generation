# -*- coding: utf-8 -*-
"""Sanskrit_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_KOjYKFBYRMnC_E5RZZdufuOpzip0VV3
"""

pip install googletrans==4.0.0-rc1

import pandas as pd
from transformers import pipeline
!pip install pdfplumber
import pdfplumber
import re
from googletrans import Translator
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import warnings
warnings.filterwarnings("ignore")

translator = Translator()
question_generator = pipeline("text2text-generation", model="valhalla/t5-small-qa-qg-hl")

# Function to extract clean text chunks from a PDF
def extract_clean_text_chunks_from_pdf(pdf_path, chunk_size=1000):
    text_chunks = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                page_text = re.sub(r'http\S+|www\S+|file:\S+|\S+\.html', '', page_text)
                page_text = re.sub(r'\s+', ' ', page_text).strip()
                for i in range(0, len(page_text), chunk_size):
                    chunk = page_text[i:i + chunk_size]
                    if chunk:
                        text_chunks.append(chunk)
    return text_chunks

# Function to translate text safely
def safe_translate(text, src, dest):
    try:
        if not text.strip():
            return ""
        return translator.translate(text, src=src, dest=dest).text
    except Exception as e:
        return ""

# Function to retrieve relevant chunks using TF-IDF
def retrieve_relevant_chunks(prompt, text_chunks, top_n=5):
    if not text_chunks:
        return []
    vectorizer = TfidfVectorizer().fit_transform([prompt] + text_chunks)
    cosine_similarities = cosine_similarity(vectorizer[0:1], vectorizer[1:]).flatten()
    top_n_indices = cosine_similarities.argsort()[-top_n:][::-1]
    return [text_chunks[i] for i in top_n_indices]

# Function to generate questions using a prompt and text chunks
def generate_questions_from_prompt_with_rag(prompt, pdf_text, total_questions=10, top_n_chunks=5, questions_per_chunk=3):
    translated_prompt = safe_translate(prompt, src='sa', dest='en')  # Translate Sanskrit prompt to English

    if not translated_prompt:
        return []

    relevant_chunks = retrieve_relevant_chunks(translated_prompt, pdf_text, top_n=top_n_chunks)

    if not relevant_chunks:
        print("No relevant chunks found.")
        return []

    all_generated_questions = []
    for chunk in relevant_chunks:
        translated_chunk = safe_translate(chunk, src='sa', dest='en')  # Translate text chunk to English
        if not translated_chunk:
            continue

        questions = question_generator(f"generate question: {translated_chunk}", num_return_sequences=questions_per_chunk)

        for q in questions:
            cleaned_question = re.sub(r'\s+', ' ', q['generated_text']).strip()
            if cleaned_question:
                all_generated_questions.append(cleaned_question)

        if len(all_generated_questions) >= total_questions:
            break

    # Translate generated questions back to Sanskrit
    translated_questions = [
        safe_translate(q, src='en', dest='sa') for q in all_generated_questions if safe_translate(q, src='en', dest='sa')
    ]

    return translated_questions[:total_questions]

# Main function for standalone execution



